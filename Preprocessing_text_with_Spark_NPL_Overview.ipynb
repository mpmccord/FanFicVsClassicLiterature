{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing text with Spark NPL-Overview.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing text with Spark NPL - Overview\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bjz-4n_vDMl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prepare Environment"
      ],
      "metadata": {
        "id": "br3PXqMvDfy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq\n",
        "\n",
        "#Install Java\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teXvoXAvDZY0",
        "outputId": "a98b20d0-169a-4fde-9f60-53f35ce74cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "#Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.6.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcGxv3YuDnx4",
        "outputId": "6d63fcd8-3650-427c-aed2-91ed7ee2bb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==2.4.4\n",
            "  Downloading pyspark-2.4.4.tar.gz (215.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7 MB 52 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 18.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130392 sha256=c1e946960d551d47780eb2f140e7d2b997319577201932559fefdbbf8701c0c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/48/19/c3b6b66e4575c164407a83bc065179904ddc33c9d6500846f0\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.6.2\n",
            "  Downloading spark_nlp-2.6.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Start Spark Session"
      ],
      "metadata": {
        "id": "py2OyUQODs-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ],
      "metadata": {
        "id": "6T94RjuTDzGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load and Read Dataset"
      ],
      "metadata": {
        "id": "7aJzJRbsD379"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, I am reading **.csv files** that I generated from the **classics** .txt files.\n",
        "These .csv files were **generated in python**, exporting the final dataframes we already built to csv.\n",
        "I am sharing these csv files **in GIT** (https://github.com/mpmccord/FanFicVsClassicLiterature/tree/main/data). \n",
        "\n",
        "There are 4 of them:\n",
        "\n",
        "\n",
        "1.   **classics_clean.csv:** The eight classics with the whole corpus, preprocessed (lower case, remove spaces, etc.)\n",
        "2.   **classics_raw.csv:**  The eight classics with the whole corpus, raw \n",
        "3.   **classics_clean_test.csv:** Subset of cleaned classics. Just two of them with only 200 words of the corpus.\n",
        "4.   **classics_raw_test.csv:** Subset of raw classics. Just two of them with only 200 words of the corpus.\n",
        "\n"
      ],
      "metadata": {
        "id": "fW9IpYkLD9FP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Read classics_raw_test.csv"
      ],
      "metadata": {
        "id": "fZ7LXjJbFYbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For testing porpuses and for short computational times, I am going to use this subset with only two incomplete raw texts"
      ],
      "metadata": {
        "id": "flQL5EQ7FjW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate Spark dataframe from csv file\n",
        "df_Spark = spark.read \\\n",
        "           .option(\"header\", True) \\\n",
        "           .csv(\"/content/drive/MyDrive/Distributed-Computing/data/classics_raw_test.csv\") #Change path accordingly to yours\n",
        "\n",
        "df_Spark.show(2, truncate=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIZ41P5iFyea",
        "outputId": "b65421dd-a742-4283-afe3-fca6b810011a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|  id|type|                                                                                                                                                                                                    text|\n",
            "+----+----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1905|   C|THE GOVERNESS OR, THE LITTLE FEMALE ACADEMY (1749) by Sarah Fielding There lived in the northern parts of England, a gentlewoman who undertook the education of young ladies and this trust she endea...|\n",
            "| 768|   C|Transcribed from the 1910 John Murray edition by David Price, email ccx074@pglaf.org WUTHERING HEIGHTS CHAPTER I 1801.--I have just returned from a visit to my landlord--the solitary neighbour that...|\n",
            "+----+----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create Pipeline"
      ],
      "metadata": {
        "id": "L9m3hBQZF8SN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create pipeline to preprocess the spark dataframe texts.\n",
        "\n",
        "Each of these classes receive an input column and creates the output column.\n",
        "At the end of the pipeline, we will have a dataframe with all of the columns that are created on the fly and their results.\n",
        "\n",
        "The **last column** generated, in this case **token_features** is the one that has all the words after being preprocessed, removing stop words, etc."
      ],
      "metadata": {
        "id": "YYzZHjoXGBs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://medium.com/spark-nlp/spark-nlp-101-document-assembler-500018f5f6b5\n",
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\") \\\n",
        "    .setCleanupMode(\"shrink_full\") #remove new lines and tabs, plus shrinking spaces and blank lines.\n",
        "\n",
        "#We dont need this because when preprocessing, the test ends up being one sentence\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "#https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp.annotator.Tokenizer.html\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "#https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\") \\\n",
        "    .setLowercase(True) \\\n",
        "    .setCleanupPatterns([\"\"\"[^A-Za-z]\"\"\"]) # remove punctuations and alphanumeric chars\n",
        "\n",
        "#Stop words used by Spark NLP: http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words\n",
        "#https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/stop-words/StopWordsCleaner.ipynb#scrollTo=1-eGocORg2ml\n",
        "stop_words = StopWordsCleaner.pretrained('stopwords_en', 'en')\\\n",
        "    .setInputCols([\"normalized\"]) \\\n",
        "    .setOutputCol(\"cleanTokens\") \\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "#https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel.html\n",
        "lemmatizer = LemmatizerModel.pretrained() \\\n",
        "         .setInputCols([\"cleanTokens\"]) \\\n",
        "         .setOutputCol(\"lemma\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"lemma\"]) \\\n",
        "    .setOutputCols([\"token_features\"]) \\\n",
        "    .setOutputAsArray(True) \\\n",
        "    .setCleanAnnotations(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRf9LnvgGQwi",
        "outputId": "f64baa8b-1b6f-4571-c018-a71e48d44d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords_en download started this may take some time.\n",
            "Approximate size to download 2.9 KB\n",
            "[OK!]\n",
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline_lr = Pipeline(\n",
        "        stages=[document, \n",
        "                sentence,\n",
        "                token,\n",
        "                normalizer,\n",
        "                stop_words, \n",
        "                lemmatizer, \n",
        "                finisher])"
      ],
      "metadata": {
        "id": "WfGrTrtZGVtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Apply Pipeline to Spark Dataframe"
      ],
      "metadata": {
        "id": "qVRtMFSvGZ7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_text = nlp_pipeline_lr.fit(df_Spark).transform(df_Spark)"
      ],
      "metadata": {
        "id": "Hf-t11ocGZhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_text.show(truncate=200) #Show results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLxlq30UGjg3",
        "outputId": "c93a4104-409e-4f7b-b584-3fc3c5155efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|  id|type|                                                                                                                                                                                                    text|                                                                                                                                                                                                document|                                                                                                                                                                                                sentence|                                                                                                                                                                                                   token|                                                                                                                                                                                              normalized|                                                                                                                                                                                             cleanTokens|                                                                                                                                                                                                   lemma|                                                                                                                                                                                          token_features|\n",
            "+----+----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1905|   C|THE GOVERNESS OR, THE LITTLE FEMALE ACADEMY (1749) by Sarah Fielding There lived in the northern parts of England, a gentlewoman who undertook the education of young ladies and this trust she endea...|[[document, 0, 1741, THE GOVERNESS OR, THE LITTLE FEMALE ACADEMY (1749) by Sarah Fielding There lived in the northern parts of England, a gentlewoman who undertook the education of young ladies and...|[[document, 0, 338, THE GOVERNESS OR, THE LITTLE FEMALE ACADEMY (1749) by Sarah Fielding There lived in the northern parts of England, a gentlewoman who undertook the education of young ladies and ...|[[token, 0, 2, THE, [sentence -> 0], []], [token, 4, 12, GOVERNESS, [sentence -> 0], []], [token, 14, 15, OR, [sentence -> 0], []], [token, 16, 16, ,, [sentence -> 0], []], [token, 18, 20, THE, [se...|[[token, 0, 2, the, [sentence -> 0], []], [token, 4, 12, governess, [sentence -> 0], []], [token, 14, 15, or, [sentence -> 0], []], [token, 18, 20, the, [sentence -> 0], []], [token, 22, 27, little...|[[token, 4, 12, governess, [sentence -> 0], []], [token, 29, 34, female, [sentence -> 0], []], [token, 36, 42, academy, [sentence -> 0], []], [token, 54, 58, sarah, [sentence -> 0], []], [token, 60...|[[token, 4, 12, governess, [sentence -> 0], []], [token, 29, 34, female, [sentence -> 0], []], [token, 36, 42, academy, [sentence -> 0], []], [token, 54, 58, sarah, [sentence -> 0], []], [token, 60...|[governess, female, academy, sarah, field, live, northern, part, england, gentlewoman, undertake, education, young, lady, trust, endeavour, faithfully, discharge, instruct, commit, care, read, writ...|\n",
            "| 768|   C|Transcribed from the 1910 John Murray edition by David Price, email ccx074@pglaf.org WUTHERING HEIGHTS CHAPTER I 1801.--I have just returned from a visit to my landlord--the solitary neighbour that...|[[document, 0, 1775, Transcribed from the 1910 John Murray edition by David Price, email ccx074@pglaf.org WUTHERING HEIGHTS CHAPTER I 1801.--I have just returned from a visit to my landlord--the so...|[[document, 0, 222, Transcribed from the 1910 John Murray edition by David Price, email ccx074@pglaf.org WUTHERING HEIGHTS CHAPTER I 1801.--I have just returned from a visit to my landlord--the sol...|[[token, 0, 10, Transcribed, [sentence -> 0], []], [token, 12, 15, from, [sentence -> 0], []], [token, 17, 19, the, [sentence -> 0], []], [token, 21, 24, 1910, [sentence -> 0], []], [token, 26, 29,...|[[token, 0, 10, transcribed, [sentence -> 0], []], [token, 12, 15, from, [sentence -> 0], []], [token, 17, 19, the, [sentence -> 0], []], [token, 26, 29, john, [sentence -> 0], []], [token, 31, 36,...|[[token, 0, 10, transcribed, [sentence -> 0], []], [token, 26, 29, john, [sentence -> 0], []], [token, 31, 36, murray, [sentence -> 0], []], [token, 38, 44, edition, [sentence -> 0], []], [token, 4...|[[token, 0, 10, transcribe, [sentence -> 0], []], [token, 26, 29, john, [sentence -> 0], []], [token, 31, 36, murray, [sentence -> 0], []], [token, 38, 44, edition, [sentence -> 0], []], [token, 49...|[transcribe, john, murray, edition, david, price, email, ccxpglaforg, wuthering, height, chapter, return, visit, landlordthe, solitary, neighbour, trouble, beautiful, country, england, fix, situati...|\n",
            "+----+----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show last column, the one that has the final result\n",
        "processed_text.select(\"token_features\").show(truncate=200) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2REFQsLHrgY",
        "outputId": "22f7c1e5-ce13-4bd9-99a0-2df160a103e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|                                                                                                                                                                                          token_features|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[governess, female, academy, sarah, field, live, northern, part, england, gentlewoman, undertake, education, young, lady, trust, endeavour, faithfully, discharge, instruct, commit, care, read, writ...|\n",
            "|[transcribe, john, murray, edition, david, price, email, ccxpglaforg, wuthering, height, chapter, return, visit, landlordthe, solitary, neighbour, trouble, beautiful, country, england, fix, situati...|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}