{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f078b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/10 17:48:09 WARN Utils: Your hostname, DSGPU05 resolves to a loopback address: 127.0.1.1; using 10.10.11.64 instead (on interface eno1)\n",
      "22/04/10 17:48:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/10 17:48:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/04/10 17:48:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfc78ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classics \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/classics_raw.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "classics = pd.read_csv(\"data/classics_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b64d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8562799",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m lines \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mclassics\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mmelt(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, value_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m\"\u001b[39m, var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_unit_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classics' is not defined"
     ]
    }
   ],
   "source": [
    "lines = (\n",
    "    classics.text.str.split(\"\\n\")\n",
    "    .apply(pd.Series)\n",
    "    .melt(ignore_index=False, value_name=\"line\", var_name=\"text_unit_id\")\n",
    "    .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "675b6a48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mclassics\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classics\u001b[38;5;241m.\u001b[39mmerge(lines, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classics' is not defined"
     ]
    }
   ],
   "source": [
    "del classics[\"text\"]\n",
    "print(classics.merge(lines, left_index=True, right_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b033636",
   "metadata": {},
   "outputs": [],
   "source": [
    "classics = classics.merge(lines, left_index=True, right_index=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classics_df = spark.createDataFrame(classics)\n",
    "classics_df.printSchema()\n",
    "classics_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bdb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, StringType, column\n",
    "import re\n",
    "def split(value):\n",
    "    punc = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    for ch in punc:\n",
    "        value = value.replace(ch, ' ')\n",
    "    return value.lower()\n",
    "def removeDigit(value):\n",
    "    digits = re.compile(\"\\{\\d+:\\d+\\}\")\n",
    "    return digits.sub(\"\", value)\n",
    "splitPunct = udf(lambda z: removeDigit(split(z)), StringType())\n",
    "removeDigits = udf(lambda z: removeDigit(z), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "classics_df = classics_df.select((\"*\"), \\\n",
    "    splitPunct(col(\"line\").alias(\"cleaned\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classics_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ded206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
    "re_tokenizer = RegexTokenizer()\n",
    "re_tokenizer.setInputCol(\"<lambda>(line AS cleaned)\").setOutputCol(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac67f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classics_df = re_tokenizer.transform(classics_df)\n",
    "classics_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "lda = LDA()\n",
    "lda.setMaxIter(10)\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49315c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.setInputCol(\"tokens\")\n",
    "cv.setOutputCol(\"vectors\")\n",
    "model = cv.fit(classics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transform(classics_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce6eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(model.vocabulary)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca43f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "td= classics_df.select(col(\"tokens\"))\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "vectorizer = CountVectorizer(inputCol=\"tokens\", outputCol=\"bag_of_words\")\n",
    "vectorizer_transformer = vectorizer.fit(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d11110",
   "metadata": {},
   "outputs": [],
   "source": [
    "?vectorizer_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector = vectorizer_transformer.transform(classics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector.select(\"bag_of_words\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_words = my_vector.select(\"bag_of_words\")\n",
    "lda.fit(bag_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ee9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
