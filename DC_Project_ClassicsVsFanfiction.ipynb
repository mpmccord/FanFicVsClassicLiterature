{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DC_Project-ClassicsVsFanfiction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "br3PXqMvDfy-",
        "Q7mjzu90Ybqw",
        "mp2beC4FYesx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Distributed Computing - Project 1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bjz-4n_vDMl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Prepare Environment"
      ],
      "metadata": {
        "id": "br3PXqMvDfy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Install Java, Pyspark and Spark NLP"
      ],
      "metadata": {
        "id": "Q7mjzu90Ybqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq\n",
        "\n",
        "#Install Java\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teXvoXAvDZY0",
        "outputId": "f4dc801d-7b3d-4363-bdd6-3bd0cc7cf940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "#Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.6.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcGxv3YuDnx4",
        "outputId": "2555c265-1675-4ce2-9c41-c655466c0ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==2.4.4\n",
            "  Downloading pyspark-2.4.4.tar.gz (215.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7 MB 54 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 19.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130392 sha256=d81ed20f93c5df3a15d9af8f0ca4e38bf5c6435ac758fbe85db20bba06bb4f5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/48/19/c3b6b66e4575c164407a83bc065179904ddc33c9d6500846f0\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.6.2\n",
            "  Downloading spark_nlp-2.6.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 8.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 Start  Spark Session"
      ],
      "metadata": {
        "id": "mp2beC4FYesx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ],
      "metadata": {
        "id": "TGDRKTctUzRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Get Classics Corpus"
      ],
      "metadata": {
        "id": "qTvaEXcQU2pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Convert txt files into Python Dataframe"
      ],
      "metadata": {
        "id": "XB-99X0IVCsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "1jCVlB2AVt1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory =\"/content/drive/MyDrive/Distributed-Computing/data/classic_literature/\" #Change according to path\n",
        "text_type = 'C'\n",
        "\n",
        "classics_df = pd.DataFrame(columns=['id', 'type', 'text'])\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "#filename = \"data/classic_literature/45.txt\"\n",
        "    file_ext = os.path.basename(filename).rsplit('.',1)[1] #Get file extension\n",
        "    if file_ext == \"txt\":\n",
        "        with open(directory + '/' + filename, 'r') as file:\n",
        "            text_id = os.path.basename(filename).rsplit('.',1)[0]\n",
        "            corpus = file.read()\n",
        "            corpus = re.sub(';', ' ', corpus)\n",
        "            corpus = corpus.replace('Chapter', '')\n",
        "            classics_df.loc[len(classics_df.index)] = [text_id, text_type, corpus]"
      ],
      "metadata": {
        "id": "6ybHiAU2Vwz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hMUL6ZGUV3U5",
        "outputId": "164d8c67-900f-47fd-cdbd-6a6d01fbe87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id type                                               text\n",
              "0   514    C  \\n\\n\\n\\nLITTLE WOMEN\\n\\n\\nby\\n\\nLouisa May Alc...\n",
              "1    45    C  \\n\\n\\n\\n\\n                  ANNE OF GREEN GABL...\n",
              "2   768    C  \\n\\n\\n\\nTranscribed from the 1910 John Murray ...\n",
              "3  1260    C  \\n\\n\\n\\n\\nTranscribed from the 1897 Service & ...\n",
              "4   145    C  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMiddlemarch\\n\\n\\...\n",
              "5  1342    C  \\n\\n\\n\\n\\nPRIDE AND PREJUDICE\\n\\nBy Jane Auste...\n",
              "6   113    C  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIn Honor of Lisa Hart's ...\n",
              "7  1905    C  \\n\\n\\n\\n\\nTHE GOVERNESS \\n\\nOR, THE LITTLE FEM..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe4f7230-e960-4428-9fc3-7460bc586525\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>514</td>\n",
              "      <td>C</td>\n",
              "      <td>\\n\\n\\n\\nLITTLE WOMEN\\n\\n\\nby\\n\\nLouisa May Alc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45</td>\n",
              "      <td>C</td>\n",
              "      <td>\\n\\n\\n\\n\\n                  ANNE OF GREEN GABL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>768</td>\n",
              "      <td>C</td>\n",
              "      <td>\\n\\n\\n\\nTranscribed from the 1910 John Murray ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1260</td>\n",
              "      <td>C</td>\n",
              "      <td>\\n\\n\\n\\n\\nTranscribed from the 1897 Service &amp; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>145</td>\n",
              "      <td>C</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMiddlemarch\\n\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1342</td>\n",
              "      <td>C</td>\n",
              "      <td>\\n\\n\\n\\n\\nPRIDE AND PREJUDICE\\n\\nBy Jane Auste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>113</td>\n",
              "      <td>C</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIn Honor of Lisa Hart's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1905</td>\n",
              "      <td>C</td>\n",
              "      <td>\\n\\n\\n\\n\\nTHE GOVERNESS \\n\\nOR, THE LITTLE FEM...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe4f7230-e960-4428-9fc3-7460bc586525')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe4f7230-e960-4428-9fc3-7460bc586525 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe4f7230-e960-4428-9fc3-7460bc586525');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Convert Python Dataframe into Spark Dataframe"
      ],
      "metadata": {
        "id": "d4O7Ft9_VVGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "#sc =  pyspark.SparkContext(\"local[*]\", \"Test Context\")\n",
        "sqlContext = SQLContext(spark)"
      ],
      "metadata": {
        "id": "eSBwrf4sVnOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Spark_classics = sqlContext.createDataFrame(classics_df) #Pyspark SQL dataframe"
      ],
      "metadata": {
        "id": "puETLHbXWG-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_Spark_classics.show()"
      ],
      "metadata": {
        "id": "ATRk8V1dXcjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Get Fanfictions Corpus"
      ],
      "metadata": {
        "id": "7tnqsgNLVqcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Convert txt files into Python Dataframe"
      ],
      "metadata": {
        "id": "O9AwiLtTX9Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory =\"/content/drive/MyDrive/Distributed-Computing/data/fanfiction/\" #Change according to path\n",
        "text_type = 'F'\n",
        "\n",
        "fanfictions_df = pd.DataFrame(columns=['id', 'type', 'text'])\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    file_ext = os.path.basename(filename).rsplit('.',1)[1] #Get file extension\n",
        "    if file_ext == \"txt\":\n",
        "        with open(directory + '/' + filename, 'r') as file:\n",
        "            text_id = os.path.basename(filename).rsplit('.',1)[0]\n",
        "            corpus = file.read()\n",
        "            corpus = corpus.replace('Chapter', '')\n",
        "            corpus = re.sub(';', ' ', corpus)\n",
        "            fanfictions_df.loc[len(fanfictions_df.index)] = [text_id, text_type, corpus]"
      ],
      "metadata": {
        "id": "q_061UaIX8Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fanfictions_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "iZ2UUw7D7QKt",
        "outputId": "819eb55a-1b3d-41b9-a469-decf732962e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                id type                                               text\n",
              "0   fanfic_7441657    F   1\\nPrologue\\nOctober 31, 1981\\nThe view out t...\n",
              "1  fanfic_33183868    F   1\\n \\n\\n \\n\\nThere was something luminescent ...\n",
              "2  fanfic_35367502    F   1\\n“Lily there’s a boy at the door!”\\nThe gin...\n",
              "3  fanfic_23824330    F   1\\nAmy sits facing the window of her room. He...\n",
              "4  fanfic_24025603    F   1\\nDisclaimer: I, by no means, claim to own a...\n",
              "5   fanfic_1536152    F   1\\nGoing back was the worst.I had hoped that,...\n",
              "6   fanfic_8523001    F   1\\nThere was such a cultural veil of secrecy ...\n",
              "7  fanfic_25042705    F   1\\n“But, really,” said Mrs. Bennet rather lou...\n",
              "8  fanfic_36819574    F   1\\nI was born in sunlight, and dragged into d..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8249770e-5c61-46e3-8ab9-3947090747ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fanfic_7441657</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\nPrologue\\nOctober 31, 1981\\nThe view out t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fanfic_33183868</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\n \\n\\n \\n\\nThere was something luminescent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fanfic_35367502</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\n“Lily there’s a boy at the door!”\\nThe gin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fanfic_23824330</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\nAmy sits facing the window of her room. He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fanfic_24025603</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\nDisclaimer: I, by no means, claim to own a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>fanfic_1536152</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\nGoing back was the worst.I had hoped that,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>fanfic_8523001</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\nThere was such a cultural veil of secrecy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>fanfic_25042705</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\n“But, really,” said Mrs. Bennet rather lou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fanfic_36819574</td>\n",
              "      <td>F</td>\n",
              "      <td>1\\nI was born in sunlight, and dragged into d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8249770e-5c61-46e3-8ab9-3947090747ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8249770e-5c61-46e3-8ab9-3947090747ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8249770e-5c61-46e3-8ab9-3947090747ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Convert Python Dataframe into Spark Dataframe"
      ],
      "metadata": {
        "id": "P_xfXM-JYCVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Spark_fanfictions = sqlContext.createDataFrame(fanfictions_df) #Pyspark SQL dataframe"
      ],
      "metadata": {
        "id": "D2nGH71mX71g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Preprocess Texts"
      ],
      "metadata": {
        "id": "675Exsu0Y3uL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Create Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "L9m3hBQZF8SN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create pipeline to preprocess the spark dataframe texts.\n",
        "\n",
        "Each of these classes receive an input column and creates the output column.\n",
        "At the end of the pipeline, we will have a dataframe with all of the columns that are created on the fly and their results.\n",
        "\n",
        "The **last column** generated, in this case **token_features** is the one that has all the words after being preprocessed, removing stop words, etc."
      ],
      "metadata": {
        "id": "YYzZHjoXGBs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://medium.com/spark-nlp/spark-nlp-101-document-assembler-500018f5f6b5\n",
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\") \\\n",
        "    .setCleanupMode(\"shrink_full\") #remove new lines and tabs, plus shrinking spaces and blank lines.\n",
        "\n",
        "#We dont need this because when preprocessing, the test ends up being one sentence\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "#https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp.annotator.Tokenizer.html\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "#https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\") \\\n",
        "    .setLowercase(True) \\\n",
        "    .setCleanupPatterns([\"\"\"[^A-Za-z]\"\"\"]) # remove punctuations and alphanumeric chars\n",
        "\n",
        "#Stop words used by Spark NLP: http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words\n",
        "#https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/stop-words/StopWordsCleaner.ipynb#scrollTo=1-eGocORg2ml\n",
        "stop_words = StopWordsCleaner.pretrained('stopwords_en', 'en')\\\n",
        "    .setInputCols([\"normalized\"]) \\\n",
        "    .setOutputCol(\"cleanTokens\") \\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "#https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel.html\n",
        "lemmatizer = LemmatizerModel.pretrained() \\\n",
        "         .setInputCols([\"cleanTokens\"]) \\\n",
        "         .setOutputCol(\"lemma\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"lemma\"]) \\\n",
        "    .setOutputCols([\"token_features\"]) \\\n",
        "    .setOutputAsArray(True) \\\n",
        "    .setCleanAnnotations(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRf9LnvgGQwi",
        "outputId": "17982f91-18cb-48db-a01b-90829528f1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords_en download started this may take some time.\n",
            "Approximate size to download 2.9 KB\n",
            "[OK!]\n",
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline_lr = Pipeline(\n",
        "        stages=[document, \n",
        "                sentence,\n",
        "                token,\n",
        "                normalizer,\n",
        "                stop_words, \n",
        "                lemmatizer, \n",
        "                finisher])"
      ],
      "metadata": {
        "id": "WfGrTrtZGVtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Apply Pipeline to Spark Dataframes"
      ],
      "metadata": {
        "id": "qVRtMFSvGZ7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.1 Classics"
      ],
      "metadata": {
        "id": "ltwYi1mQcgv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_classics_df = nlp_pipeline_lr.fit(df_Spark_classics).transform(df_Spark_classics)"
      ],
      "metadata": {
        "id": "Hf-t11ocGZhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do not execute the line below - Takes long and the output is very big.\n",
        "#Execute next cell instead, which only includes the result of interest: Token features\n",
        "\n",
        "#processed_classics_df.show(truncate=200) #Show results"
      ],
      "metadata": {
        "id": "tLxlq30UGjg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show Token Features column\n",
        "processed_classics_df.select(\"token_features\").show(truncate=200) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2REFQsLHrgY",
        "outputId": "528f6e73-1310-4327-c03f-eef8a24a8799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|                                                                                                                                                                                          token_features|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[woman, louisa, alcott, content, part, play, pilgrim, merry, christmas, laurence, boy, burden, neighborly, beth, find, palace, beautiful, amy, valley, humiliation, jo, meet, apollyon, meg, vanity, ...|\n",
            "|[anne, green, gable, lucy, maud, montgomery, table, content, chapter, mrs, rachel, lynde, surprise, chapter, ii, matthew, cuthbert, surprise, chapter, iii, marilla, cuthbert, surprise, chapter, iv,...|\n",
            "|[transcribe, john, murray, edition, david, price, email, ccxpglaforg, wuthering, height, chapter, return, visit, landlordthe, solitary, neighbour, trouble, beautiful, country, england, fix, situati...|\n",
            "|[transcribe, service, paton, edition, david, price, email, ccxpglaforg, jane, eyre, autobiography, charlotte, bronte, illustrate, townsend, london, service, paton, henrietta, street, illustration, ...|\n",
            "|[middlemarch, george, eliot, york, boston, caldwell, company, publisher, dear, husband, george, henry, lewes, nineteenth, year, bless, union, content, book, chapter, chapter, ii, chapter, iii, chap...|\n",
            "|[pride, prejudice, jane, austen, truth, universally, acknowledge, single, man, possession, good, fortune, wife, feelings, view, man, enter, neighbourhood, truth, fix, mind, surround, family, consid...|\n",
            "|[honor, lisa, hart, birthday, secret, garden, frances, hodgson, burnett, author, shuttle, make, marchioness, method, lady, walderhurst, lass, lowries, administration, lord, fauntleroy, lady, qualit...|\n",
            "|[governess, female, academy, sarah, field, live, northern, part, england, gentlewoman, undertake, education, young, lady, trust, endeavour, faithfully, discharge, instruct, commit, care, read, writ...|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.2 Fanfictions"
      ],
      "metadata": {
        "id": "XqE2UdOXckMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_fanfictions_df = nlp_pipeline_lr.fit(df_Spark_fanfictions).transform(df_Spark_fanfictions)"
      ],
      "metadata": {
        "id": "Wp76EXcM75Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_fanfictions_df.select(\"token_features\").show(truncate=200) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAA3y6207_v1",
        "outputId": "29e70238-742f-4189-bdf1-aac7f4fb916b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|                                                                                                                                                                                          token_features|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[prologue, october, view, window, dark, moon, day, sliver, white, show, sky, electric, light, window, look, small, rear, yard, shelter, streetlight, traffic, enclose, buildings, fence, small, room,...|\n",
            "|[luminescent, susie, draw, noelles, eye, walk, hallway, susie, step, noelle, deer, want, desperately, close, distance, eye, ahead, couldnt, steal, glance, girl, walk, steal, glance, susie, notice, ...|\n",
            "|[lily, boy, door, ginger, haired, girl, quickly, shoulder, sister, back, glass, front, door, boy, curly, dark, brown, black, hair, hard, dark, past, large, round, glass, hair, bit, messy, fall, ear...|\n",
            "|[amy, sit, face, window, room, phone, prop, desk, litter, wide, sheet, art, paper, pencil, color, amy, phone, amy, marena, fancy, artist, amy, face, fall, dramatically, tone, turn, sharply, sarcast...|\n",
            "|[disclaimer, mean, claim, remotely, relate, glee, pitch, perfect, universe, copyright, infringement, intend, chloe, beale, expect, senior, year, high, school, start, true, young, didnt, give, think...|\n",
            "|[back, worsti, hope, case, i, id, move, school, luck, trip, locker, positive, consequence, whatsoever, back, school, month, iti, force, foot, push, class, door, opendont, give, satisfaction, tell, ...|\n",
            "|[cultural, veil, secrecy, draw, soulmark, miss, elizabeth, bennett, visit, mrs, charlotte, collins, ne, lucas, kent, charlotte, ribbon, glove, bracelet, sleeve, leave, wrist, blank, elizabeth, asto...|\n",
            "|[mrs, bennet, loudly, place, teacup, back, saucer, loud, clink, young, man, income, search, wife, waste, money, spend, child, wife, mrs, lucas, nod, agreement, reach, hand, touch, brim, wide, hat, ...|\n",
            "|[bear, sunlight, drag, darkness, child, pure, cursedi, watch, woman, love, wither, front, close, eye, truth, order, avoid, pain, itand, father, move, life, indulge, part, sort, debauchery, money, c...|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "s6AFS8-N8c1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point we have two preprocessed Spark Dataframes where each row belongs two one book. The column of interest is **\"token_features\"**, which contains all the **tokens** of the corpus.\n",
        "\n",
        "1.   **processed_classics_df**: Contains the eiight classics (one per row)\n",
        "2.   **processed_fanfictions_df**: Contains the eiight fanfictions (one per row)\n",
        "\n",
        "--> From here, we can start doing additional processing like TF-IDF or other stuff to obtain the information we want.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lU_z5wJ38f5e"
      }
    }
  ]
}